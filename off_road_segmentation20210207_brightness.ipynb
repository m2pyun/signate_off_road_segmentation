{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "off_road_segmentation20210124_1639.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m2pyun/signate_off_road_segmentation/blob/main/off_road_segmentation20210207_brightness.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzLLYiTEyyjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f186aec-4e51-4f18-8b28-1460fc8b21ab"
      },
      "source": [
        "!git clone https://github.com/m2pyun/signate_off_road_segmentation.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'signate_off_road_segmentation'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 53 (delta 6), reused 45 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHUirHsJFoJc"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)#2. Get the file"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAy6E4NT2uoR"
      },
      "source": [
        "train_A0 = drive.CreateFile({'id':'1amBnDtdmfwe6E4fMsD-9XuJPac9H2bwI'}) # replace the id with id of file you want to access\n",
        "train_A1 = drive.CreateFile({'id':'1wl_vj4UlECr9NkdpzeP6PUj8T66OICyH'})\n",
        "train_A2 = drive.CreateFile({'id':'1unrPOKP2GH1LVhlwDh1ypZ3_Do5UibvX'})\n",
        "train_A3 = drive.CreateFile({'id':'1_mNWROSr7IZ24SeGMBT2ECKKfSd0ABXj'})\n",
        "annotation_A = drive.CreateFile({'id':'1fFShS85-VxdkhJt58ngJxnicP6W8e3ew'})\n",
        "train_A0.GetContentFile('train_A0.zip')\n",
        "train_A1.GetContentFile('train_A1.zip')\n",
        "train_A2.GetContentFile('train_A2.zip')\n",
        "train_A3.GetContentFile('train_A3.zip')\n",
        "annotation_A.GetContentFile('annotation_A.zip')\n",
        "\n",
        "\n",
        "!unzip train_A0.zip -d off_road\n",
        "!unzip train_A1.zip -d off_road\n",
        "!unzip train_A2.zip -d off_road\n",
        "!unzip train_A3.zip -d off_road\n",
        "!unzip annotation_A.zip -d off_road"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etzIT1V37Vj1"
      },
      "source": [
        "precision = drive.CreateFile({'id':'1MN8kwpPPN-BUsJKnrkiuofv8UdejY3ki'})\n",
        "precision.GetContentFile('precision.zip')\n",
        "!unzip precision.zip -d off_road"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv0Ijr58XSEW"
      },
      "source": [
        "tutorial_model = drive.CreateFile({'id':'1jtE9PTopW5sSZA6rO20_5u8fz2zQLWs0'})\n",
        "tutorial_model.GetContentFile('tutorial_model.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvE-bZ-KyPeu",
        "outputId": "53db718b-8a92-4f45-e259-51971ef5f23f"
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams['font.sans-serif'] = ['Hiragino Maru Gothic Pro', 'Yu Gothic', 'Meirio', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "import random\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "# 評価対象カテゴリ\n",
        "eval_names = ('road','dirt road', 'other obstacle')\n",
        "eval_colors = ((128, 64, 128), (255, 128, 128), (0, 0, 70))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7.0+cu101\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Cbi-MMd3j4m",
        "outputId": "6496b4b3-8d74-41af-93fd-f3ec53170b82"
      },
      "source": [
        "train_images_path_list = sorted(glob('off_road/train_images_A*/*.png'))\n",
        "train_annotations_path_list = sorted(glob('off_road/train_annotations_A/*.png'))\n",
        "print('================')\n",
        "print('学習用画像: ')\n",
        "print(len(train_images_path_list))\n",
        "print(train_images_path_list[:5])\n",
        "print('================')\n",
        "print('学習用アノテーション: ')\n",
        "print(len(train_annotations_path_list))\n",
        "print(train_annotations_path_list[:5])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================\n",
            "学習用画像: \n",
            "3007\n",
            "['off_road/train_images_A_0/train_image_A0000.png', 'off_road/train_images_A_0/train_image_A0001.png', 'off_road/train_images_A_0/train_image_A0002.png', 'off_road/train_images_A_0/train_image_A0003.png', 'off_road/train_images_A_0/train_image_A0004.png']\n",
            "================\n",
            "学習用アノテーション: \n",
            "3007\n",
            "['off_road/train_annotations_A/train_annotation_A0000.png', 'off_road/train_annotations_A/train_annotation_A0001.png', 'off_road/train_annotations_A/train_annotation_A0002.png', 'off_road/train_annotations_A/train_annotation_A0003.png', 'off_road/train_annotations_A/train_annotation_A0004.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vDisV1W49cn",
        "outputId": "2093b446-a938-4403-bc17-f6fbd81d67a3"
      },
      "source": [
        "precision_test_images_path_list = sorted(glob('off_road/precision_test_images/*.png'))\n",
        "\n",
        "print('================')\n",
        "print('精度評価用画像: ')\n",
        "print(len(precision_test_images_path_list))\n",
        "print(precision_test_images_path_list[:5])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================\n",
            "精度評価用画像: \n",
            "640\n",
            "['off_road/precision_test_images/precision_test_image_0000.png', 'off_road/precision_test_images/precision_test_image_0001.png', 'off_road/precision_test_images/precision_test_image_0002.png', 'off_road/precision_test_images/precision_test_image_0003.png', 'off_road/precision_test_images/precision_test_image_0004.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "v3__dabo49Zd",
        "outputId": "f04183b1-674e-42a2-8ee1-a6145b91550b"
      },
      "source": [
        "# 画像の読み込み\n",
        "\n",
        "image_0000 = Image.open('off_road/train_images_A/train_image_A0000.png')\n",
        "annotation_0000 = Image.open('off_road/train_annotations_A/train_annotation_A0000.png')\n",
        "\n",
        "# 可視化\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 10))\n",
        "\n",
        "axes[0].imshow(image_0000)\n",
        "axes[0].set_title('train_image_A0000.png')\n",
        "\n",
        "axes[1].imshow(annotation_0000)\n",
        "axes[1].set_title('train_annotation_A0000.png')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0218494dfb7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 画像の読み込み\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimage_0000\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off_road/train_images_A*/train_image_A0000.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mannotation_0000\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off_road/train_annotations_A/train_annotation_A0000.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2809\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2810\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'off_road/train_images_A*/train_image_A0000.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "WIgCToTq49Rs",
        "outputId": "53a429fe-6164-4b13-ecf2-40d358f57299"
      },
      "source": [
        "count = {\n",
        "    'road': 0,\n",
        "    'dirt road': 0,\n",
        "    'other obstacle':0\n",
        "}\n",
        "\n",
        "for train_annotation_path in train_annotations_path_list:\n",
        "    image = np.array(Image.open(train_annotation_path))\n",
        "    \n",
        "    for eval_name, eval_color in zip(eval_names, eval_colors):\n",
        "        mask = (image==eval_color).sum(axis=2)==3\n",
        "        if np.any(mask):\n",
        "            count[eval_name] += 1\n",
        "            \n",
        "plt.bar(count.keys(), count.values())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-19e72ab6b40b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0meval_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_color\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_colors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0meval_color\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meval_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3_so-4J49OK"
      },
      "source": [
        "class OffRoadTransform():\n",
        "    def __init__(self, image_size, mean, std):\n",
        "        self.image_size = image_size\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        \n",
        "    def __call__(self, image, annotation):\n",
        "        \n",
        "        # リサイズ\n",
        "        image = image.resize((self.image_size[1], self.image_size[0]))        \n",
        "        annotation = annotation.resize((self.image_size[1], self.image_size[0]))\n",
        "\n",
        "        #明るさ\n",
        "        rand_n = random.randint(0, 10)\n",
        "        if rand_n > 9:\n",
        "            brightness = 0.8\n",
        "            brightness_factor = np.random.uniform(max(0, 1 - brightness), 1 + brightness)\n",
        "            image = transforms.functional.adjust_brightness(image, brightness_factor)\n",
        "      \n",
        "        # テンソル化&標準化\n",
        "        image = transforms.functional.to_tensor(image)\n",
        "        image = transforms.functional.normalize(image, self.mean, self.std)\n",
        "        \n",
        "        # アノテーション画像の色(RGB)情報を以下のように対応するようマッピングし、2次元の配列に変換する\n",
        "        \"\"\"\n",
        "        road(128, 64, 128) -> 1\n",
        "        dirt road(255, 128, 128) -> 2\n",
        "        other obstacle(0, 0, 70) -> 3\n",
        "        上記以外 -> 0\n",
        "        \"\"\"\n",
        "        annotation = np.array(annotation)\n",
        "        converted_annotation = np.zeros(annotation.shape[:-1])\n",
        "        for i, eval_color in enumerate(eval_colors):\n",
        "            mask = (annotation==eval_color).sum(axis=2)==3\n",
        "            converted_annotation[mask] = i+1\n",
        "        annotation = torch.from_numpy(converted_annotation)\n",
        "        \n",
        "        return image, annotation"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRx3AZCA49LF"
      },
      "source": [
        "class OffRoadDataset(data.Dataset):\n",
        "    def __init__(self, image_list, annotation_list, transform):\n",
        "        self.image_list = image_list\n",
        "        self.annotation_list = annotation_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        image_filepath = self.image_list[index]\n",
        "        annotation_filepath = self.annotation_list[index]\n",
        "        \n",
        "        image = Image.open(image_filepath)\n",
        "        annotation = Image.open(annotation_filepath)\n",
        "\n",
        "        image, annotation = self.transform(image, annotation)\n",
        "        \n",
        "        return image, annotation\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwBb8Sjp49G-",
        "outputId": "f6cfb5a9-fc04-49a2-c61e-16979730ace2"
      },
      "source": [
        "train_dataset = OffRoadDataset(train_images_path_list, train_annotations_path_list,\n",
        "                              transform=OffRoadTransform(image_size=(270, 480), mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)))\n",
        "\n",
        "print(train_dataset.__getitem__(0)[0].shape)\n",
        "print(train_dataset.__getitem__(0)[1].shape)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 270, 480])\n",
            "torch.Size([270, 480])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Iv8ejQzBVX7"
      },
      "source": [
        "batch_size = 4\n",
        "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMv3q7L_AZAz"
      },
      "source": [
        "net = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjYxy4xKwtDH"
      },
      "source": [
        "net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLGjfVJpAY-A"
      },
      "source": [
        "net.classifier[-1] = nn.Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM6hf36LW3v-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR2IHcCeYo-6"
      },
      "source": [
        "# 学習済みモデルの読み込み\n",
        "net = pd.read_pickle(\"tutorial_model.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewph7_NgAY7x"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters())"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOPPFlXHAY5i"
      },
      "source": [
        "def train(net, train_dataloader, criterion, optimizer, n_epoch):\n",
        "    \n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(device)\n",
        "    \n",
        "    net.to(device)\n",
        "    net.train()\n",
        "\n",
        "    for epoch in range(1, n_epoch+1):\n",
        "        epoch_train_loss = 0.0\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        for images, annotations in train_dataloader:\n",
        "            images = images.to(device)\n",
        "            annotations = annotations.to(device)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = net(images)['out']\n",
        "                loss = criterion(outputs, annotations.long())\n",
        "                loss.backward()\n",
        "                \n",
        "        print(f'Epoch {epoch} finished')\n",
        "\n",
        "    pd.to_pickle(net, \"tutorial_model.pkl\".format(n_epoch))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "1c6fM6eyAY3I",
        "outputId": "72a21956-3b4e-4eca-b424-0be6c89b2fde"
      },
      "source": [
        "train(net, train_dataloader, criterion, optimizer, n_epoch=2)\n",
        "from google.colab import files\n",
        "files.download(\"tutorial_model.pkl\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Epoch 1 finished\n",
            "Epoch 2 finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3db976ba-a67d-49c2-9eb2-851824507124\", \"tutorial_model.pkl\", 244641675)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpLwqEmRAY0i"
      },
      "source": [
        "# 学習済みモデルの読み込み\n",
        "net = pd.read_pickle(\"tutorial_model_0207.pkl\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTMbCEuvAYvv"
      },
      "source": [
        "# デバイスの設定\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net.to(device)\n",
        "net.eval()\n",
        "\n",
        "# 前処理クラスのインスタンス化\n",
        "test_transform = OffRoadTransform(image_size=(270, 480), mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "\n",
        "# 画像データの読み込み\n",
        "test_image_0000 = Image.open('off_road/precision_test_images/precision_test_image_0000.png')\n",
        "dummy_annotation = Image.open('off_road/train_annotations_A/train_annotation_A0000.png')\n",
        "\n",
        "image_transformed, _ = test_transform(test_image_0000, dummy_annotation)\n",
        "image_transformed = image_transformed.unsqueeze(0)\n",
        "image_transformed = image_transformed.to(device)\n",
        "\n",
        "# 推論の実行\n",
        "prediction = net(image_transformed)['out']\n",
        "prediction = prediction[0].to('cpu').detach().numpy()\n",
        "prediction = np.argmax(prediction, axis=0).astype('uint8')\n",
        "prediction = np.array(Image.fromarray(prediction).resize([1920, 1080]))\n",
        "\n",
        "# 推論結果をRGB画像に変換\n",
        "RGB = np.zeros([1080, 1920, 3], dtype='uint8')\n",
        "for i, color in enumerate(eval_colors):\n",
        "    mask = prediction==i+1\n",
        "    RGB[mask] = color\n",
        "RGB_prediction = np.array(Image.fromarray(RGB).resize([1920, 1080]))\n",
        "\n",
        "# 可視化\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 10))\n",
        "\n",
        "axes[0].imshow(test_image_0000)\n",
        "axes[0].set_title('元画像')\n",
        "\n",
        "axes[1].imshow(RGB_prediction)\n",
        "axes[1].set_title('予測結果')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSRYqHbKAYtU"
      },
      "source": [
        "def pred2dict(fname, prediction):\n",
        "    categories = [('road',[128, 64, 128]),('dirt road',[255, 128, 128]),('other obstacle',[0, 0, 70])]\n",
        "    pred_dict = {}\n",
        "    pred_dict[fname]={}\n",
        "    \n",
        "    for i,category in enumerate(categories):\n",
        "\n",
        "        category_segments_pred = {}\n",
        "        x_pred, y_pred = np.where(prediction==(i+1))\n",
        "        category_pix_pred = {}\n",
        "\n",
        "        for i,j in zip(x_pred,y_pred):\n",
        "            if i not in category_pix_pred:\n",
        "                category_pix_pred[i]=[]\n",
        "            category_pix_pred[i].append(j)   \n",
        "\n",
        "        for l in category_pix_pred:\n",
        "            segments = []\n",
        "            num_segments = 0\n",
        "            for i,v in enumerate(sorted(category_pix_pred[l])):\n",
        "                if i==0:\n",
        "                    start=v\n",
        "                    end=v\n",
        "                else:\n",
        "                    if v==end+1:\n",
        "                        end = v\n",
        "                    else:\n",
        "                        segments.append([int(start),int(end)])\n",
        "                        start = v\n",
        "                        end = v\n",
        "                        num_segments+=1\n",
        "            segments.append([int(start),int(end)])\n",
        "            category_segments_pred[int(l)]=segments\n",
        "        if len(category_pix_pred):\n",
        "            pred_dict[fname][category[0]]=category_segments_pred\n",
        "        \n",
        "    return pred_dict"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkWxuHY0AYqm"
      },
      "source": [
        "def make_submission_file():\n",
        "    \n",
        "    categories = [('road',[128, 64, 128]),('dirt road',[255, 128, 128]),('other obstacle',[0, 0, 70])]\n",
        "    predictions = {}\n",
        "    \n",
        "    # デバイスの設定\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    net.to(device)\n",
        "    \n",
        "    net.eval()\n",
        "    \n",
        "    # 前処理クラスのインスタンス化\n",
        "    test_transform = OffRoadTransform(image_size=(270, 480), mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "    \n",
        "    # 画像一枚ずつに対して処理を実行するループ\n",
        "    for test_image_path in precision_test_images_path_list:\n",
        "        \n",
        "        fname = os.path.basename(test_image_path)\n",
        "        test_image = Image.open(test_image_path)\n",
        "        dummy_annotation = Image.open('off_road/train_annotations_A/train_annotation_A0000.png')\n",
        "        test_image, _ = test_transform(test_image, dummy_annotation)\n",
        "        \n",
        "        # ミニバッチ化\n",
        "        test_image = test_image.unsqueeze(0).to(device)\n",
        "        \n",
        "        # 推論の実行\n",
        "        prediction = net(test_image)['out']\n",
        "        prediction = prediction[0].to('cpu').detach().numpy()\n",
        "        prediction = np.argmax(prediction, axis=0).astype('uint8')\n",
        "        prediction = np.array(Image.fromarray(prediction).resize([1920, 1080]))\n",
        "        \n",
        "        # 関数pred2dictを用いて予測画像を辞書形式に変換\n",
        "        pred_dict = pred2dict(fname, prediction)\n",
        "        predictions.update(pred_dict)\n",
        "\n",
        "    with open(f'tutorial_submission_0207.json', 'w') as f:\n",
        "        json.dump(predictions, f)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp95Ehh549EM"
      },
      "source": [
        "make_submission_file()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AZxjwYI49AH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}